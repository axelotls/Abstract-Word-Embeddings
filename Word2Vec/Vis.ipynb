{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b04842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# load word vectors\n",
    "word_vectors = gensim.models.Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# create list of projection data\n",
    "# tuple (label, vector)\n",
    "labels = word_vectors.wv.index_to_key\n",
    "vectors = [word_vectors.wv[label] for label in labels]\n",
    "\n",
    "projection_data = [(label, vector) for label, vector in zip(labels, vectors)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e653a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 14:12:39.724811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-01 14:12:39.724869: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-01 14:12:52.149665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-01 14:12:52.149761: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-01 14:12:52.149812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (august-OptiPlex-3040): /proc/driver/nvidia/version does not exist\n",
      "2023-08-01 14:12:52.171719: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "def create_projection(projection_data, path='./tensorboard/'):\n",
    "    meta_file = 'metadata.tsv'\n",
    "    samples = len(projection_data)\n",
    "    vector_dim = len(projection_data[0][1])\n",
    "    projection_matrix = np.zeros((samples, vector_dim))\n",
    "\n",
    "    # write meta file with labels, create projection_matrix\n",
    "    with open(os.path.join(path, meta_file), 'w') as f:\n",
    "        for i, row in enumerate(projection_data):\n",
    "            label, vector = row[0], row[1]\n",
    "            projection_matrix[i] = vector\n",
    "            f.write(f\"{label}\\n\")\n",
    "\n",
    "    weights = tf.Variable(\n",
    "        projection_matrix, trainable=False, name='word_embeddings'\n",
    "    )\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "    checkpoint.save(os.path.join(path, \"embedding.ckpt\"))\n",
    "    writer = tf.summary.create_file_writer(path)\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = meta_file\n",
    "    projector.visualize_embeddings(path, config)\n",
    "\n",
    "create_projection(projection_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ab0cb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 98666), started 0:45:23 ago. (Use '!kill 98666' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d4d2eecda5fcd5c4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d4d2eecda5fcd5c4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"./tensorboard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5052b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: umap in /home/august/.local/lib/python3.10/site-packages (0.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bokeh in /home/august/.local/lib/python3.10/site-packages (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (1.23.5)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/lib/python3/dist-packages (from bokeh) (21.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/lib/python3/dist-packages (from bokeh) (5.4.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (2.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (9.5.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/august/.local/lib/python3.10/site-packages (from bokeh) (6.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/august/.local/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/august/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/august/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/august/.local/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/august/.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/august/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/august/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/august/.local/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/august/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: umap-learn in /home/august/.local/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (1.23.5)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (0.5.10)\n",
      "Requirement already satisfied: numba>=0.49 in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (0.57.1)\n",
      "Requirement already satisfied: tqdm in /home/august/.local/lib/python3.10/site-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/august/.local/lib/python3.10/site-packages (from numba>=0.49->umap-learn) (0.40.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/august/.local/lib/python3.10/site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/august/.local/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install umap\n",
    "%pip install bokeh\n",
    "%pip install pandas\n",
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355932e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/august/.local/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/august/.local/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/august/.local/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/august/.local/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "2023-08-01 15:06:25.585106: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-01 15:06:25.585176: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Category20, Turbo256\n",
    "import umap\n",
    "from bokeh.models import Label\n",
    "from bokeh.models import ColumnDataSource, Label, LabelSet, Range1d\n",
    "from bokeh.plotting import figure, output_file, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0352bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_plot(umap_embedding_df, words_to_highlight=[], splits=[], fn=None):\n",
    "    datasource = ColumnDataSource(umap_embedding_df)\n",
    "    # define color mapping\n",
    "    palette = []\n",
    "    if words_to_highlight:\n",
    "        if not splits:\n",
    "            l = len(words_to_highlight)\n",
    "            if 256 > l > 20:\n",
    "                palette = [Turbo256[i] for i in range(0, 256, int(256/l))][:l]\n",
    "            elif l <= 20:\n",
    "                palette = Category20[l]\n",
    "                words_to_highlight = words_to_highlight[:l]\n",
    "            else:\n",
    "                print('too many words to highlight.')\n",
    "                return\n",
    "        else:\n",
    "            colors = Category20[20]\n",
    "            if len(splits) == 3:\n",
    "                #                red               blue              green\n",
    "                colors = [Category20[20][6], Category20[20][0], Category20[20][4]]\n",
    "            palette = [0] * len(words_to_highlight)\n",
    "            start = 0\n",
    "            for i, end in enumerate(splits):\n",
    "                palette[start:end] = [colors[i]] * (end - start)\n",
    "                start = end\n",
    "\n",
    "    print(palette)\n",
    "    color_mapping = CategoricalColorMapper(factors=words_to_highlight, palette=palette)\n",
    "\n",
    "    plot_figure = figure(\n",
    "        title='UMAP projection of word embeddings',\n",
    "        # plot_width=600,\n",
    "        # plot_height=600,\n",
    "        tools=('pan, wheel_zoom, reset')\n",
    "    )\n",
    "\n",
    "    plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "    <div>\n",
    "        <div>\n",
    "            <span style='font-size: 16px; color: #224499'>Word:</span>\n",
    "            <span style='font-size: 18px'>@Word</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    if fn is not None:\n",
    "        output_file(filename=fn, title='UMAP projection of word embeddings')\n",
    "\n",
    "    plot_figure.circle(\n",
    "        'x',\n",
    "        'y',\n",
    "        source=datasource,\n",
    "        color=dict(field='Word', transform=color_mapping),\n",
    "        line_alpha=0.6,\n",
    "        fill_alpha=0.6,\n",
    "        size=7\n",
    "    )\n",
    "    if fn is not None:\n",
    "        save(plot_figure)\n",
    "    else:\n",
    "        show(plot_figure)\n",
    "\n",
    "\n",
    "def generate_umap_embedding(labels, word_embeddings):\n",
    "    # collapse embeddings to two dimensions\n",
    "    reducer = umap.UMAP()\n",
    "    reducer.fit(word_embeddings)\n",
    "    umap_embedding = reducer.transform(word_embeddings)\n",
    "\n",
    "    # put data in a data frame\n",
    "    umap_df = pd.DataFrame(umap_embedding, columns=['x', 'y'])\n",
    "    umap_df.index = labels\n",
    "    umap_df.index.name = \"Word\"\n",
    "\n",
    "    return umap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648824f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=14031, vector_size=150, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7c5b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = generate_umap_embedding(labels, vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b520da33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# catalyst_names = ['Cp*Ti(OBz)3','Cp2ZrCl2','Cp2ZrCl','Cp2HfCl2','Cp2TiCl2','EtInd2ZrCl2','(nBuCp)2ZrCl2','Et[Ind]2ZrCl2','Et(Ind)2ZrCl2','(n-BuCp)2ZrCl2','(SBI)ZrMe2', 'Cp2TiMe2','Cp2ZrMe2','Cp2HfMe2','Me2SiInd2ZrCl2','CpZrCl3','CpTiCl3','CpHfCl3','Cl4Ti','Cp*ZrMe3']\n",
    "# activator_names = ['MAO','TIBA','TEA','TIBAO','MMAO','methylaluminoxane','triethylaluminum','triisobutylaluminum','Et3Al','AlEtCl2','AlEt2Cl','tris(pentafluorophenyl)borane', '[CPh3][B(C6F5)4]','CPh3B(C6F5)4','ethylaluminoxane','tetrachloroaluminate','tri-isobutylaluminum','methyl-aluminoxane','tetrakis(pentafluorophenyl)borane']\n",
    "# monomer_names = ['propene', 'ethene', '1-butene', '1,7-octadiene', '1-hexene', '1-dodecene', '1-decene', '1-octene']\n",
    "# keywords = [\"polymer\", \"polymerization\", \"metallocene\", \"metallocenes\"]\n",
    "# highlight = []\n",
    "# for cat in catalyst_names:\n",
    "#     highlight.append(cat)\n",
    "# for act in activator_names:\n",
    "#     highlight.append(act)\n",
    "# for mon in monomer_names:\n",
    "#     highlight.append(mon)\n",
    "# for w in keywords:\n",
    "#     highlight.append(w)\n",
    "\n",
    "# df = df[df.Word.isin(highlight)]\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69000919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "catalyst_names = ['Cp*Ti(OBz)3','Cp2ZrCl2','Cp2ZrCl','Cp2HfCl2','Cp2TiCl2','EtInd2ZrCl2','(nBuCp)2ZrCl2','Et[Ind]2ZrCl2','Et(Ind)2ZrCl2','(n-BuCp)2ZrCl2','(SBI)ZrMe2', 'Cp2TiMe2','Cp2ZrMe2','Cp2HfMe2','Me2SiInd2ZrCl2','CpZrCl3','CpTiCl3','CpHfCl3','Cl4Ti','Cp*ZrMe3']\n",
    "activator_names = ['MAO','TIBA','TEA','TIBAO','MMAO','methylaluminoxane','triethylaluminum','triisobutylaluminum','Et3Al','AlEtCl2','AlEt2Cl','tris(pentafluorophenyl)borane', '[CPh3][B(C6F5)4]','CPh3B(C6F5)4','ethylaluminoxane','tetrachloroaluminate','tri-isobutylaluminum','methyl-aluminoxane','tetrakis(pentafluorophenyl)borane']\n",
    "monomer_names = ['propene', 'ethene', '1-butene', '1,7-octadiene', '1-hexene', '1-dodecene', '1-decene', '1-octene']\n",
    "keywords = [\"polymer\", \"polymerization\", \"metallocene\", \"metallocenes\"]\n",
    "highlight = [catalyst.lower() for catalyst in catalyst_names] + [activator.lower() for activator in activator_names] + [monomer.lower() for monomer in monomer_names] + keywords\n",
    "\n",
    "for catalyst in catalyst_names:\n",
    "    print(catalyst.lower() in df.index)\n",
    "\n",
    "df = df[df.index.isin(highlight)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628ff776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement arrange_data (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for arrange_data\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arrange_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall arrange_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marrange_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_to_list\n\u001b[1;32m      3\u001b[0m in_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([catalyst\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mfor\u001b[39;00m catalyst \u001b[38;5;129;01min\u001b[39;00m catalyst_names])\n\u001b[1;32m      4\u001b[0m in_abstracts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([catalyst \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(file_to_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/abstracts.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m catalyst \u001b[38;5;129;01min\u001b[39;00m catalyst_names])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arrange_data'"
     ]
    }
   ],
   "source": [
    "%pip install arrange_data\n",
    "from arrange_data import file_to_list\n",
    "in_data = np.array([catalyst.lower() in df.index for catalyst in catalyst_names])\n",
    "in_abstracts = np.array([catalyst in ' '.join(file_to_list(\"data/abstracts.txt\")) for catalyst in catalyst_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bc16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cff27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interactive_plot(df,highlight,[len(catalyst_names), len(catalyst_names) + len(activator_names), len(catalyst_names) + len(activator_names) + len(monomer_names), len(highlight)], fn='2dvis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs('Cp2ZrCl2'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
